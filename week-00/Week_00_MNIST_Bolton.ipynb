{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week-00-MNIST-Bolton.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boltonhowes22/image-segmentation-ehg/blob/master/week-00/Week_00_MNIST_Bolton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bytGIhpN7tKG",
        "colab_type": "code",
        "outputId": "3bfe50a0-9634-4b96-f12c-965ec97fdc47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# First we are going to make sure we are using the most up to date version of tensorflow\n",
        "try:\n",
        "# %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "# Tensorboard is a cool visualization component of tensorflow. \n",
        "# helps keep track of training metrics\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Import tensorflow and datetime and TensorBoard\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mph4S1h976Gl",
        "colab_type": "code",
        "outputId": "3a5d366d-59f1-4de6-84e7-583fe0a4c772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Load Dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# Split Dataset into training and testing\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# normalize pixel values to between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "## Need to reshape for convolutional neural network\n",
        "# reshape data to fit model\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "img_rows = x_train[0].shape[0]\n",
        "img_cols = x_train[0].shape[1]\n",
        "\n",
        "# Define number of classes--MNIST has 10\n",
        "num_classes = 10\n",
        "\n",
        "# one-hot encode target\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Properly shapes the data if it is messed up\n",
        "if tf.keras.backend.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuVyi1GN-bov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmxON1qu7_qr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a function to build a model \n",
        "def create_model():\n",
        "  return tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Conv2D(32, kernel_size=(11, 11), activation='relu', input_shape=input_shape, name='conv1'),\n",
        "            tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
        "            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "            tf.keras.layers.Dropout(0.25),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(128,activation='relu'),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            tf.keras.layers.Dense(num_classes,activation='sigmoid')],\n",
        "            \n",
        "            )\n",
        "\n",
        "  # Hyperparameters\n",
        "num_epochs = 15   # An epoch is the number of times the network will see each instance of training data\n",
        "batch_size = 256\n",
        "optimizer = 'adam'\n",
        "loss = 'categorical_crossentropy'\n",
        "metrics = 'accuracy'\n",
        "#initial_learning_rate = 0.0008\n",
        "#lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "#    initial_learning_rate,\n",
        "#    decay_steps=round(60000/batch_size),\n",
        "#    decay_rate=0.9,\n",
        "#    staircase=True)\n",
        "\n",
        "#optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.999, amsgrad=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcPJOyFOqRWB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d2b0b57-2bc1-4c3d-96c7-4ee5e4ef14a3"
      },
      "source": [
        "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./log', histogram_freq=1,\n",
        "#                        write_graph=True,\n",
        "#                        write_grads=True, \n",
        "#                        #batch_size=batch_size,\n",
        "#                        write_images=True)\n",
        "#\n",
        "#model\n",
        "round(60000/128)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "469"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPNq8rtr8C40",
        "colab_type": "code",
        "outputId": "879b788f-9b15-4a5f-ba6a-270474dff2a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "model = create_model()\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss,\n",
        "              metrics=[metrics])\n",
        "\n",
        "\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir ) # , histogram_freq=1)\n",
        "\n",
        "model.fit(x=x_train, \n",
        "          y=y_train, \n",
        "          epochs=num_epochs,\n",
        "          batch_size=batch_size, \n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[tensorboard_callback]\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 91s 2ms/sample - loss: 0.4501 - accuracy: 0.8713 - val_loss: 0.0742 - val_accuracy: 0.9760\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 90s 2ms/sample - loss: 0.1248 - accuracy: 0.9656 - val_loss: 0.0460 - val_accuracy: 0.9848\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 90s 1ms/sample - loss: 0.0870 - accuracy: 0.9753 - val_loss: 0.0380 - val_accuracy: 0.9875\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 90s 2ms/sample - loss: 0.0679 - accuracy: 0.9809 - val_loss: 0.0324 - val_accuracy: 0.9893\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 90s 1ms/sample - loss: 0.0576 - accuracy: 0.9833 - val_loss: 0.0296 - val_accuracy: 0.9905\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 90s 1ms/sample - loss: 0.0485 - accuracy: 0.9855 - val_loss: 0.0275 - val_accuracy: 0.9914\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 89s 1ms/sample - loss: 0.0446 - accuracy: 0.9872 - val_loss: 0.0267 - val_accuracy: 0.9908\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 89s 1ms/sample - loss: 0.0377 - accuracy: 0.9885 - val_loss: 0.0251 - val_accuracy: 0.9917\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 90s 1ms/sample - loss: 0.0342 - accuracy: 0.9903 - val_loss: 0.0241 - val_accuracy: 0.9919\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 90s 1ms/sample - loss: 0.0320 - accuracy: 0.9904 - val_loss: 0.0288 - val_accuracy: 0.9909\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 89s 1ms/sample - loss: 0.0303 - accuracy: 0.9908 - val_loss: 0.0261 - val_accuracy: 0.9924\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 90s 1ms/sample - loss: 0.0287 - accuracy: 0.9909 - val_loss: 0.0247 - val_accuracy: 0.9926\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 90s 1ms/sample - loss: 0.0256 - accuracy: 0.9918 - val_loss: 0.0259 - val_accuracy: 0.9926\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 90s 1ms/sample - loss: 0.0251 - accuracy: 0.9923 - val_loss: 0.0244 - val_accuracy: 0.9919\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 89s 1ms/sample - loss: 0.0233 - accuracy: 0.9924 - val_loss: 0.0248 - val_accuracy: 0.9930\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f88c989a160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81f2cU5N8D47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT0b2Jiam8sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}